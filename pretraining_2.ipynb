{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:12.737103Z","iopub.execute_input":"2025-05-16T17:50:12.737318Z","iopub.status.idle":"2025-05-16T17:50:12.751024Z","shell.execute_reply.started":"2025-05-16T17:50:12.737294Z","shell.execute_reply":"2025-05-16T17:50:12.746574Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom tqdm import tqdm\nfrom torch.cuda.amp import GradScaler, autocast\nimport uuid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:12.752058Z","iopub.execute_input":"2025-05-16T17:50:12.752270Z","iopub.status.idle":"2025-05-16T17:50:16.381839Z","shell.execute_reply.started":"2025-05-16T17:50:12.752250Z","shell.execute_reply":"2025-05-16T17:50:16.376948Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\nprint(f\"Number of TPU cores available: {xm.xrt_world_size()}\")\nprint(f\"Current TPU ordinal: {xm.get_ordinal()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:16.384032Z","iopub.execute_input":"2025-05-16T17:50:16.384657Z","iopub.status.idle":"2025-05-16T17:50:20.411302Z","shell.execute_reply.started":"2025-05-16T17:50:16.384629Z","shell.execute_reply":"2025-05-16T17:50:20.405467Z"}},"outputs":[{"name":"stderr","text":"WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1747417818.089569    2990 common_lib.cc:621] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:232\nWARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n","output_type":"stream"},{"name":"stdout","text":"Number of TPU cores available: 1\nCurrent TPU ordinal: 0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# TPU-specific imports\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:20.413363Z","iopub.execute_input":"2025-05-16T17:50:20.413722Z","iopub.status.idle":"2025-05-16T17:50:20.427902Z","shell.execute_reply.started":"2025-05-16T17:50:20.413698Z","shell.execute_reply":"2025-05-16T17:50:20.420941Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data Loading and Preprocessing\nbase_path = '/kaggle/input/data'\nimage_dirs = [f'images_{str(i).zfill(3)}' for i in range(1, 13)]\ndata_entry_csv_path = os.path.join(base_path, 'Data_Entry_2017.csv')\n\n# Load metadata\ndata_entry_df = pd.read_csv(data_entry_csv_path)\ndata_entry_df = data_entry_df.loc[:, ~data_entry_df.columns.str.contains('^Unnamed')]\nprint(f\"Total data entries: {len(data_entry_df)}\")\n\nclass SSLCustomDataset(Dataset):\n    def __init__(self, df, image_dirs, base_path, target_size=(224, 224)):\n        self.df = df\n        self.image_dirs = image_dirs\n        self.base_path = base_path\n        self.target_size = target_size\n        \n        self.image_path_map = self._build_image_path_map()\n        self.valid_indices = [i for i in range(len(df)) if self.image_path_map.get(df.iloc[i]['Image Index'])]\n        print(f\"Filtered dataset to {len(self.valid_indices)} valid images\")\n\n        self.transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomResizedCrop(target_size, scale=(0.5, 1.0)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.1, 0.1, 0.1, 0.05)\n            ], p=0.5),\n            transforms.RandomGrayscale(p=0.1),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                               std=[0.229, 0.224, 0.225])\n        ])\n    def _build_image_path_map(self):\n        path_map = {}\n        for dir_name in self.image_dirs:\n            dir_path = os.path.join(self.base_path, dir_name, 'images')\n            if os.path.exists(dir_path):\n                for img_file in os.listdir(dir_path):\n                    path_map[img_file] = os.path.join(dir_path, img_file)\n        return path_map\n    \n    def __len__(self):\n        return len(self.valid_indices)\n    \n\n    def __getitem__(self, idx):\n        idx = self.valid_indices[idx]\n        row = self.df.iloc[idx]\n        img_path = self.image_path_map[row['Image Index']]\n        \n        img = cv2.imread(img_path)\n        if img is None:\n            raise ValueError(f\"Failed to load image: {img_path}\")\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        img1 = self.transform(img)\n        img2 = self.transform(img)\n        \n        return img1, img2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:20.430717Z","iopub.execute_input":"2025-05-16T17:50:20.431046Z","iopub.status.idle":"2025-05-16T17:50:20.664901Z","shell.execute_reply.started":"2025-05-16T17:50:20.431023Z","shell.execute_reply":"2025-05-16T17:50:20.660390Z"}},"outputs":[{"name":"stdout","text":"Total data entries: 112120\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Model Definitions\nclass Encoder(nn.Module):\n    def __init__(self):\n        super(Encoder, self).__init__()\n        self.resnet = models.resnet18(weights='IMAGENET1K_V1')\n        self.resnet.fc = nn.Identity()\n\n    def forward(self, x):\n        return self.resnet(x)\n\nclass MLPHead(nn.Module):\n    def __init__(self, in_dim=512, hidden_dim=512, out_dim=128):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim, bias=False),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, out_dim, bias=False),\n            nn.BatchNorm1d(out_dim, affine=False)\n        )\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n\n    def forward(self, x):\n        z = self.net(x)\n        return F.normalize(z, dim=1)\n        \nclass SSLModel(nn.Module):\n    def __init__(self, encoder):\n        super().__init__()\n        self.encoder = encoder\n        self.projector = MLPHead()\n\n    def forward(self, x1, x2):\n        h1 = self.encoder(x1)\n        h2 = self.encoder(x2)\n        z1 = self.projector(h1)\n        z2 = self.projector(h2)\n        return z1, z2\n        \nclass NTXentLoss(nn.Module):\n    def __init__(self, temperature=0.1):  \n        super().__init__()\n        self.temperature = temperature\n        \n    def forward(self, z1, z2):\n        batch_size = z1.size(0)\n        features = torch.cat([z1, z2], dim=0)\n        similarity = torch.mm(features, features.t()) / self.temperature\n        \n        pos_sim = torch.diag(similarity, batch_size)\n        if torch.rand(1).item() < 0.01:\n            xm.master_print(f\"Positive similarity: {pos_sim.mean().item():.4f}\")\n        \n        mask = torch.eye(2 * batch_size, device=similarity.device)\n        mask = 1 - mask\n        similarity = similarity * mask\n        \n        labels = torch.zeros(2 * batch_size, device=similarity.device, dtype=torch.int64)\n        labels[0:batch_size] = torch.arange(batch_size, 2*batch_size)\n        labels[batch_size:2*batch_size] = torch.arange(0, batch_size)\n        \n        loss = F.cross_entropy(similarity, labels)\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:50:20.667284Z","iopub.execute_input":"2025-05-16T17:50:20.667571Z","iopub.status.idle":"2025-05-16T17:50:20.686690Z","shell.execute_reply.started":"2025-05-16T17:50:20.667545Z","shell.execute_reply":"2025-05-16T17:50:20.680945Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Training function adapted for TPU\ndef train():\n    device = xm.xla_device()\n    # Create dataset and dataloader\n    batch_size = 128 * xm.xrt_world_size()  # Scale batch size with number of cores\n    dataset = SSLCustomDataset(data_entry_df, image_dirs, base_path)\n    sampler = torch.utils.data.distributed.DistributedSampler(\n        dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True)\n    \n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        sampler=sampler,\n        num_workers=4,\n        drop_last=True)\n    \n    # Wrap with parallel loader\n    device_loader = pl.MpDeviceLoader(dataloader, device)\n\n    # Instantiate model\n    model = SSLModel(Encoder()).to(device)\n    criterion = NTXentLoss(temperature=0.1).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3 * xm.xrt_world_size())  # Scale learning rate\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n    scaler = GradScaler()\n\n    num_epochs = 5\n    accum_steps = 16\n    print_freq = 200\n    \n    for epoch in range(num_epochs):\n        model.train()\n        sampler.set_epoch(epoch)\n        total_loss = 0\n        batch_count = 0\n        \n        for batch_idx, (img1, img2) in enumerate(tqdm(device_loader, \n                                                    desc=f\"Epoch {epoch + 1}/{num_epochs}\",\n                                                    disable=not xm.is_master_ordinal())):\n            with autocast():\n                z1, z2 = model(img1, img2)\n                loss = criterion(z1, z2) / accum_steps\n\n            scaler.scale(loss).backward()\n            \n            if (batch_idx + 1) % print_freq == 0 and xm.is_master_ordinal():\n                # Removed cosine similarity computation and printing\n                xm.master_print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}, Loss: {loss.item() * accum_steps:.4f}\")\n            \n            if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(dataloader):\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                xm.mark_step()  # Important for TPU execution\n\n            total_loss += loss.item() * accum_steps\n            batch_count += 1\n\n        scheduler.step()\n        avg_loss = total_loss / batch_count\n        xm.master_print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n\n        if xm.is_master_ordinal():\n            torch.save(model.state_dict(), f\"ssl_model_epoch_{epoch + 1}.pth\")\n\n    if xm.is_master_ordinal():\n        final_save_path = 'ssl_model_final.pth'\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'encoder_architecture': 'resnet18',\n            'projector_dims': [512, 512, 128],\n        }, final_save_path)\n        print(f\"Training complete! Model saved to {final_save_path}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:57:27.719706Z","iopub.execute_input":"2025-05-16T17:57:27.720044Z","iopub.status.idle":"2025-05-16T17:57:27.741054Z","shell.execute_reply.started":"2025-05-16T17:57:27.720014Z","shell.execute_reply":"2025-05-16T17:57:27.736218Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Start training\ndef _mp_fn(rank, flags):\n    # Initialize TPU inside the spawned process\n    device = xm.xla_device()\n    print(f\"TPU {rank}: Device {device} initialized\")\n    train()\n# Launch TPU training\nFLAGS = {}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs= 1, start_method='fork')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:57:27.955846Z","iopub.execute_input":"2025-05-16T17:57:27.956183Z","iopub.status.idle":"2025-05-16T19:23:49.428747Z","shell.execute_reply.started":"2025-05-16T17:57:27.956156Z","shell.execute_reply":"2025-05-16T19:23:49.423507Z"}},"outputs":[{"name":"stdout","text":"TPU 0: Device xla:0 initialized\nFiltered dataset to 112120 valid images\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:   2%|▏         | 14/875 [00:20<08:35,  1.67it/s] ","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 3.2744\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:   3%|▎         | 26/875 [00:38<27:17,  1.93s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 7.7182\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:   9%|▉         | 80/875 [01:35<06:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 8.7845\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  10%|▉         | 84/875 [01:43<13:56,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 8.9183\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  11%|█         | 93/875 [01:53<10:03,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 8.7356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  23%|██▎       | 199/875 [03:55<05:05,  2.21it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Batch 200, Loss: 0.4092\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  24%|██▍       | 213/875 [04:13<08:39,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.1403\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  35%|███▍      | 302/875 [06:11<06:46,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.1510\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  45%|████▍     | 392/875 [08:13<03:21,  2.39it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 1/5:  46%|████▌     | 399/875 [08:25<04:19,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Batch 400, Loss: 0.3014\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  56%|█████▋    | 494/875 [10:38<04:19,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.2466\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  68%|██████▊   | 599/875 [13:02<02:23,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Batch 600, Loss: 0.1250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  83%|████████▎ | 728/875 [15:58<01:03,  2.33it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.3909\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  85%|████████▍ | 740/875 [16:19<02:46,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.3665\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  85%|████████▍ | 742/875 [16:19<01:33,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4453\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  91%|█████████▏| 799/875 [17:35<00:39,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Batch 800, Loss: 0.0886\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:  97%|█████████▋| 848/875 [18:42<00:13,  1.95it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 1/5: 100%|██████████| 875/875 [19:14<00:00,  1.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Average Loss: 0.4438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  17%|█▋        | 152/875 [02:55<04:31,  2.66it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 2/5:  23%|██▎       | 199/875 [03:48<04:55,  2.29it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Batch 200, Loss: 0.0774\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  23%|██▎       | 203/875 [03:56<15:06,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4385\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  27%|██▋       | 233/875 [04:32<29:25,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4773\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  34%|███▎      | 295/875 [05:39<04:27,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5065\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  39%|███▉      | 345/875 [06:43<24:12,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  46%|████▌     | 399/875 [07:39<03:39,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Batch 400, Loss: 0.0673\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  50%|█████     | 441/875 [08:32<18:52,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4498\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  55%|█████▍    | 478/875 [09:11<03:54,  1.69it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4767\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  55%|█████▍    | 479/875 [09:11<03:09,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4630\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  56%|█████▌    | 488/875 [09:20<02:24,  2.68it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 2/5:  64%|██████▍   | 559/875 [10:42<02:19,  2.27it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4101\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  67%|██████▋   | 587/875 [11:17<06:52,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4942\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  68%|██████▊   | 599/875 [11:27<02:07,  2.16it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Batch 600, Loss: 0.0715\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  88%|████████▊ | 771/875 [14:48<02:23,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4690\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  91%|█████████▏| 799/875 [15:16<00:34,  2.23it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Batch 800, Loss: 0.0607\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5:  94%|█████████▎| 819/875 [15:43<01:14,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4693\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 875/875 [16:41<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Average Loss: 0.0738\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  16%|█▌        | 137/875 [02:46<31:26,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5516\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  19%|█▊        | 163/875 [03:13<16:25,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4889\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  23%|██▎       | 199/875 [03:50<05:12,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Batch 200, Loss: 0.0598\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  23%|██▎       | 205/875 [03:59<08:36,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4556\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  25%|██▌       | 223/875 [04:18<04:57,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4853\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  31%|███       | 268/875 [05:13<10:20,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5762\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  44%|████▎     | 381/875 [07:20<06:15,  1.32it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 3/5:  46%|████▌     | 399/875 [07:39<03:36,  2.20it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Batch 400, Loss: 0.0539\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  68%|██████▊   | 599/875 [11:28<02:07,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Batch 600, Loss: 0.0556\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  69%|██████▉   | 608/875 [11:38<02:02,  2.19it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 3/5:  85%|████████▍ | 743/875 [14:14<00:59,  2.20it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.6012\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5:  91%|█████████▏| 799/875 [15:18<00:34,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Batch 800, Loss: 0.0500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 875/875 [16:45<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Average Loss: 0.0540\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:   7%|▋         | 61/875 [01:14<10:03,  1.35it/s] ","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5679\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  23%|██▎       | 199/875 [03:48<05:08,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Batch 200, Loss: 0.0475\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  25%|██▍       | 216/875 [04:06<04:03,  2.70it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 4/5:  30%|██▉       | 262/875 [05:01<05:46,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.4946\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  43%|████▎     | 376/875 [07:10<03:03,  2.72it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5175\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  46%|████▌     | 399/875 [07:37<03:40,  2.16it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5629\nEpoch 4/5, Batch 400, Loss: 0.0409\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  58%|█████▊    | 511/875 [09:47<02:48,  2.16it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5960\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  68%|██████▊   | 591/875 [11:17<02:09,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5614\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  68%|██████▊   | 599/875 [11:26<02:05,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Batch 600, Loss: 0.0435\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  71%|███████   | 621/875 [11:52<03:05,  1.37it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 4/5:  74%|███████▎  | 644/875 [12:20<03:52,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5426\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  89%|████████▉ | 780/875 [14:52<01:36,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5514\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  91%|█████████▏| 799/875 [15:11<00:35,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Batch 800, Loss: 0.0442\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  94%|█████████▍| 822/875 [15:39<00:31,  1.68it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5485\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  96%|█████████▌| 840/875 [15:59<00:13,  2.60it/s]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5262\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5:  97%|█████████▋| 851/875 [16:17<00:32,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5741\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 875/875 [16:39<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5, Average Loss: 0.0456\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:   3%|▎         | 28/875 [00:39<14:57,  1.06s/it] ","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5745\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  23%|██▎       | 199/875 [03:53<05:08,  2.19it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Batch 200, Loss: 0.0453\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  23%|██▎       | 201/875 [04:02<30:01,  2.67s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5783\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  26%|██▌       | 226/875 [04:29<21:32,  1.99s/it]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 5/5:  32%|███▏      | 276/875 [05:26<10:11,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5925\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  46%|████▌     | 399/875 [07:44<03:39,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Batch 400, Loss: 0.0460\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  68%|██████▊   | 599/875 [11:34<02:06,  2.18it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Batch 600, Loss: 0.0378\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  72%|███████▏  | 628/875 [12:11<04:14,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Positive similarity: 9.5025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5:  90%|████████▉ | 784/875 [15:08<00:41,  2.17it/s]libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\nEpoch 5/5:  91%|█████████▏| 799/875 [15:26<00:35,  2.15it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Batch 800, Loss: 0.0416\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 875/875 [16:52<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5, Average Loss: 0.0427\nTraining complete! Model saved to ssl_model_final.pth\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}